# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WPluoKr_-0EsJY9kh9jfUkqIGIrSFqqw

# Multilingual_Caption_Aligner_Validator
## Prompt:
### Write a Python script that accepts a dataset of image-caption pairs in English and automatically generates corresponding captions in a user-specified target language (e.g., Urdu, Spanish, Chinese) using the Hugging Face transformers translation pipeline. Then, validate that the translated captions preserve core semantic meaning by comparing the cosine similarity between the sentence embeddings of the original and translated captions using a multilingual sentence encoder (e.g., LaBSE). Discard translations with similarity < 0.75.

## Deliverables:
### Translation function
### Similarity scoring module
### Output: JSON or CSV with {image_path, en_caption, lang_caption, similarity}
"""

import pandas as pd

df = pd.read_csv("/content/Flickr30k_captions.csv", delimiter='|')
df.columns = ['image', 'comment_number', 'comment']
df['image'] = df['image'].str.strip()
df['comment'] = df['comment'].str.strip()

df.dropna(subset=['comment'], inplace=True)

# Group captions
captions_dict = df.groupby('image')['comment'].apply(list).to_dict()

df

captions_dict

import pandas as pd

# Choose only the first caption for each image
caption_data = [
    {
        'image_path': f"/content/flickr30k_images/{img}",  # <-- update this path if needed
        'en_caption': captions[0]  # first caption per image
    }
    for img, captions in captions_dict.items()
]

# Convert to DataFrame
df_captions = pd.DataFrame(caption_data)

# Save if needed
df_captions.to_csv("/content/flickr30k_first_caption.csv", index=False)

# Preview
df_captions

# Preview
import pandas as pd
df_captions=pd.read_csv("/content/flickr30k_first_caption.csv")
df_captions

from tqdm import tqdm
tqdm.pandas()

from transformers import MarianMTModel, MarianTokenizer, pipeline

# Map target languages to MarianMT model names
MARIAN_MODELS = {
    'ur': 'Helsinki-NLP/opus-mt-en-ur',   # English → Urdu
    'es': 'Helsinki-NLP/opus-mt-en-es',   # English → Spanish
    'zh': 'Helsinki-NLP/opus-mt-en-zh',   # English → Chinese
}

# Cache for loaded models to avoid reloading
_translation_pipelines = {}

def translate_caption(en_caption, target_lang):
    """
    Translates a single English caption to the target language using MarianMT.

    Parameters:
        en_caption (str): The English caption.
        target_lang (str): Target language code (e.g., 'ur', 'es', 'zh').

    Returns:
        str: Translated caption.
    """
    if target_lang not in MARIAN_MODELS:
        raise ValueError(f"Unsupported language: {target_lang}")

    model_name = MARIAN_MODELS[target_lang]

    # Lazy-load and cache translation pipeline
    if target_lang not in _translation_pipelines:
        tokenizer = MarianTokenizer.from_pretrained(model_name)
        model = MarianMTModel.from_pretrained(model_name)
        translator = pipeline("translation", model=model, tokenizer=tokenizer)
        _translation_pipelines[target_lang] = translator
    else:
        translator = _translation_pipelines[target_lang]

    # Translate and return the result
    translated = translator(en_caption, max_length=128, truncation=True)
    return translated[0]['translation_text']

caption = "A young girl is playing with a red ball."
print("Spanish:", translate_caption(caption, 'es'))
print("Urdu:", translate_caption(caption, 'ur'))
print("Chinese:", translate_caption(caption, 'zh'))

df_captions = df_captions.head(3000)
df_captions

from tqdm import tqdm
tqdm.pandas()

# Apply translations
df_captions['caption_es'] = df_captions['en_caption'].progress_apply(lambda x: translate_caption(x, 'es'))
df_captions['caption_zh'] = df_captions['en_caption'].progress_apply(lambda x: translate_caption(x, 'zh'))
df_captions['caption_ur'] = df_captions['en_caption'].progress_apply(lambda x: translate_caption(x, 'ur'))

# Save results
df_captions.to_csv('/content/flickr30k_translated_3k_sentences.csv', index=False)

# Preview
df_captions

# Preview
import pandas as pd
data_captions=pd.read_csv("/content/flickr30k_translated_3k_sentences.csv")
data_captions

!pip install sentence-transformers scikit-learn

import pandas as pd
import torch
from sentence_transformers import SentenceTransformer, util


# Load LaBSE model and move to GPU if available
device = 'cuda' if torch.cuda.is_available() else 'cpu'
labse = SentenceTransformer('sentence-transformers/LaBSE').to(device)

# Choose target language column
target_language = 'caption_es'

# Get sentences
en_sentences = data_captions['en_caption'].tolist()
translated_sentences = data_captions[target_language].tolist()

# Encode both sets of captions
print("Encoding sentences...")
emb_en = labse.encode(en_sentences, convert_to_tensor=True, device=device, batch_size=64)
emb_translated = labse.encode(translated_sentences, convert_to_tensor=True, device=device, batch_size=64)

# Compute cosine similarity
similarities = util.cos_sim(emb_en, emb_translated).diagonal().cpu().numpy()

# Add similarity column to DataFrame
data_captions['similarity'] = similarities
print("Filtering sentences with similarity >= 0.75...")

# Filter based on threshold
filtered_df = data_captions[data_captions['similarity'] >= 0.75].reset_index(drop=True)

# Save the result
output_path = f"/content/filtered_captions_{target_language}.csv"
filtered_df.to_csv(output_path, index=False)

# Summary
print(f"✔️ Kept {len(filtered_df)} / {len(data_captions)} translations with similarity ≥ 0.75")
print(f"Saved to: {output_path}")

filtered_df



import pandas as pd
import torch
from sentence_transformers import SentenceTransformer, util


# Load LaBSE model and move to GPU if available
device = 'cuda' if torch.cuda.is_available() else 'cpu'
labse = SentenceTransformer('sentence-transformers/LaBSE').to(device)

# Choose target language column
target_language = 'caption_zh'

# Get sentences
en_sentences = data_captions['en_caption'].tolist()
translated_sentences = data_captions[target_language].tolist()

# Encode both sets of captions
print("Encoding sentences...")
emb_en = labse.encode(en_sentences, convert_to_tensor=True, device=device, batch_size=64)
emb_translated = labse.encode(translated_sentences, convert_to_tensor=True, device=device, batch_size=64)

# Compute cosine similarity
similarities = util.cos_sim(emb_en, emb_translated).diagonal().cpu().numpy()

# Add similarity column to DataFrame
data_captions['similarity'] = similarities
print("Filtering sentences with similarity >= 0.75...")

# Filter based on threshold
filtered_df = data_captions[data_captions['similarity'] >= 0.75].reset_index(drop=True)

# Save the result
output_path = f"/content/filtered_captions_{target_language}.csv"
filtered_df.to_csv(output_path, index=False)

# Summary
print(f"✔️ Kept {len(filtered_df)} / {len(data_captions)} translations with similarity ≥ 0.75")
print(f"Saved to: {output_path}")


filtered_df

import pandas as pd
import torch
from sentence_transformers import SentenceTransformer, util


# Load LaBSE model and move to GPU if available
device = 'cuda' if torch.cuda.is_available() else 'cpu'
labse = SentenceTransformer('sentence-transformers/LaBSE').to(device)

# Choose target language column
target_language = 'caption_ur'

# Get sentences
en_sentences = data_captions['en_caption'].tolist()
translated_sentences = data_captions[target_language].tolist()

# Encode both sets of captions
print("Encoding sentences...")
emb_en = labse.encode(en_sentences, convert_to_tensor=True, device=device, batch_size=64)
emb_translated = labse.encode(translated_sentences, convert_to_tensor=True, device=device, batch_size=64)

# Compute cosine similarity
similarities = util.cos_sim(emb_en, emb_translated).diagonal().cpu().numpy()

# Add similarity column to DataFrame
data_captions['similarity'] = similarities
print("Filtering sentences with similarity >= 0.75...")

# Filter based on threshold
filtered_df = data_captions[data_captions['similarity'] >= 0.75].reset_index(drop=True)

# Save the result
output_path = f"/content/filtered_captions_{target_language}.csv"
filtered_df.to_csv(output_path, index=False)

# Summary
print(f"✔️ Kept {len(filtered_df)} / {len(data_captions)} translations with similarity ≥ 0.75")
print(f"Saved to: {output_path}")


filtered_df















"""# Cross-Lingual Prompt Cycle Evaluator
## Prompt:
### Build a function that accepts a prompt in any target language (e.g., Chinese), translates it to English, and then back-translates it into the original language using two separate translation models. Compare the final back-translated sentence with the original using token-level edit distance and character-level BLEU score. Highlight mismatches and compute an explainability score (0 to 1) indicating how well the meaning was preserved.
## Deliverables:
### Translation pipeline
### Scoring module with token-level comparison
### CLI-based report output
"""

!pip install transformers sacrebleu nltk python-Levenshtein termcolor

from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM
from termcolor import colored

# MarianMT forward translation models
MARIAN_FORWARD = {
    'zh': 'Helsinki-NLP/opus-mt-zh-en',
    'ur': 'Helsinki-NLP/opus-mt-ur-en',
    'es': 'Helsinki-NLP/opus-mt-es-en',
}

# mBART language codes
MBART_LANG_CODES = {
    'zh': 'zh_CN',
    'ur': 'ur_PK',
    'es': 'es_XX',
}

# Load MarianMT forward translator
def get_marian_translator(lang_code):
    return pipeline("translation", model=MARIAN_FORWARD[lang_code], device=0)

# Load mBART back translator (en → target)
def get_mbart_back_translator(target_lang_code):
    model_name = 'facebook/mbart-large-50-many-to-many-mmt'
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to("cuda")

    def translate_func(english_text):
        tokenizer.src_lang = "en_XX"
        inputs = tokenizer(english_text, return_tensors="pt", truncation=True, padding=True).to("cuda")
        generated_tokens = model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[MBART_LANG_CODES[target_lang_code]])
        return tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]

    return translate_func

# Round-trip translation using MarianMT → mBART
def round_trip_translate(prompt, lang_code):
    # Forward: target lang → English
    to_en_pipe = get_marian_translator(lang_code)
    english = to_en_pipe(prompt, truncation=True)[0]['translation_text']

    # Backward: English → target lang (via mBART)
    back_translate_func = get_mbart_back_translator(lang_code)
    back_translated = back_translate_func(english)

    return english, back_translated

from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction
import Levenshtein as lev

def token_edit_distance(original, back_translated):
    original_tokens = original.split()
    back_tokens = back_translated.split()
    return lev.distance(" ".join(original_tokens), " ".join(back_tokens)), original_tokens, back_tokens

def char_bleu_score(original, back_translated):
    reference = list(original)
    candidate = list(back_translated)
    return sentence_bleu([reference], candidate, smoothing_function=SmoothingFunction().method1)

def compute_explainability_score(original, back_translated):
    edit_dist, orig_tokens, back_tokens = token_edit_distance(original, back_translated)
    max_len = max(len(orig_tokens), len(back_tokens), 1)
    token_score = 1 - (edit_dist / max_len)
    bleu_score = char_bleu_score(original, back_translated)
    return 0.6 * token_score + 0.4 * bleu_score, orig_tokens, back_tokens

def show_report(prompt, lang_code):
    print(colored(f"\n🌐 Original Prompt ({lang_code}):", "cyan"))
    print(prompt)

    english, back_trans = round_trip_translate(prompt, lang_code)

    print(colored("\n🇬🇧 English Translation:", "yellow"))
    print(english)

    print(colored(f"\n🔁 Back-Translated to {lang_code}:", "green"))
    print(back_trans)

    score, orig_tokens, back_tokens = compute_explainability_score(prompt, back_trans)

    print(colored("\n🧠 Token Comparison:", "magenta"))
    for o, b in zip(orig_tokens, back_tokens):
        if o != b:
            print(colored(f"- {o} ≠ {b}", "red"))
        else:
            print(colored(f"- {o} == {b}", "green"))

    print(colored(f"\n📊 Explainability Score: {score:.2f} (1 = perfect meaning preservation)", "blue"))

show_report("你在公园做什么？", lang_code='zh')

show_report("تم پارک میں کیا کر رہے ہو؟", lang_code='ur')

show_report("¿Qué estás haciendo en el parque?", lang_code='es')

"""# Prompt Paraphrase Discriminator
## Prompt:
### Design a binary classifier that takes two prompts in the same or different languages and predicts whether they describe the same visual scene.
### Train on manually curated pairs (e.g., “a red bicycle under a tree” vs. “a red cycle parked beneath a tree” or their translations) using embeddings from LaBSE or mT5. Ensure the system is robust to paraphrasing, synonyms, and language-specific expressions. Use at least one evaluation metric such as ROC-AUC.
## Deliverables:
### Dataset creation strategy
### Classification model and training code
### Evaluation report
"""

# Preview
import pandas as pd
data_captions=pd.read_csv("/content/flickr30k_translated_3k_sentences.csv")
data_captions

import pandas as pd
import random

data = pd.read_csv("/content/flickr30k_translated_3k_sentences.csv")

# Positive pairs
positive_pairs = []
for _, row in data.iterrows():
    positive_pairs.append((row['en_caption'], row['caption_es'], 1))
    positive_pairs.append((row['en_caption'], row['caption_zh'], 1))
    positive_pairs.append((row['en_caption'], row['caption_ur'], 1))

# Negative pairs (random mismatches)
negative_pairs = []
for _ in range(len(positive_pairs)):
    i, j = random.sample(range(len(data)), 2)
    cap1 = data.iloc[i]['en_caption']
    cap2 = data.iloc[j][random.choice(['caption_es', 'caption_zh', 'caption_ur'])]
    negative_pairs.append((cap1, cap2, 0))

# Combine and shuffle
all_pairs = positive_pairs + negative_pairs
random.shuffle(all_pairs)

df_pairs = pd.DataFrame(all_pairs, columns=["caption1", "caption2", "label"])
df_pairs

from sentence_transformers import SentenceTransformer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, accuracy_score, classification_report
import numpy as np

# Load LaBSE
model = SentenceTransformer("sentence-transformers/LaBSE")

# Compute embeddings
def get_features(df):
    emb1 = model.encode(df['caption1'].tolist(), convert_to_tensor=False, batch_size=64)
    emb2 = model.encode(df['caption2'].tolist(), convert_to_tensor=False, batch_size=64)

    # Use element-wise absolute difference + multiplication as features
    return np.concatenate([np.abs(np.array(emb1) - np.array(emb2)), np.array(emb1) * np.array(emb2)], axis=1)

# Prepare features and labels
X = get_features(df_pairs)
y = df_pairs['label'].values

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Classifier
clf = LogisticRegression(max_iter=1000)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
y_prob = clf.predict_proba(X_test)[:, 1]

print("Accuracy:", accuracy_score(y_test, y_pred))
print("ROC-AUC:", roc_auc_score(y_test, y_prob))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

import torch
import numpy as np
from torch.utils.data import DataLoader, TensorDataset, random_split
from sentence_transformers import SentenceTransformer
import pandas as pd
import random


# Load LaBSE
labse = SentenceTransformer("sentence-transformers/LaBSE")

# Embed both captions
emb1 = labse.encode(df_pairs['caption1'].tolist(), batch_size=64, convert_to_tensor=True)
emb2 = labse.encode(df_pairs['caption2'].tolist(), batch_size=64, convert_to_tensor=True)

# Feature combination: |A - B| and A * B
features = torch.cat([torch.abs(emb1 - emb2), emb1 * emb2], dim=1)
labels = torch.tensor(df_pairs['label'].values).long()

# Dataset and split
dataset = TensorDataset(features, labels)
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_ds, val_ds = random_split(dataset, [train_size, val_size])

train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)
val_loader = DataLoader(val_ds, batch_size=64)

import torch
import torch.nn as nn

model = nn.Sequential(
    nn.Linear(1536, 512),  # FIXED
    nn.ReLU(),
    nn.Dropout(0.2),
    nn.Linear(512, 128),
    nn.ReLU(),
    nn.Linear(128, 2)
).to("cuda")

import torch.optim as optim
from sklearn.metrics import accuracy_score, roc_auc_score

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=2e-4)

def evaluate(model, loader):
    model.eval()
    preds, targets = [], []
    with torch.no_grad():
        for xb, yb in loader:
            xb, yb = xb.cuda(), yb.cuda()
            out = model(xb)
            pred = out.argmax(dim=1).cpu().numpy()
            prob = torch.softmax(out, dim=1)[:, 1].cpu().numpy()
            preds.extend(list(zip(pred, prob)))
            targets.extend(yb.cpu().numpy())
    pred_labels, pred_probs = zip(*preds)
    acc = accuracy_score(targets, pred_labels)
    auc = roc_auc_score(targets, pred_probs)
    return acc, auc

# Train
for epoch in range(5):
    model.train()
    for xb, yb in train_loader:
        xb, yb = xb.cuda(), yb.cuda()
        optimizer.zero_grad()
        out = model(xb)
        loss = criterion(out, yb)
        loss.backward()
        optimizer.step()

    acc, auc = evaluate(model, val_loader)
    print(f"Epoch {epoch+1}: Accuracy={acc:.4f}, ROC-AUC={auc:.4f}")



import torch
import numpy as np
from torch.utils.data import DataLoader, TensorDataset, random_split
from sentence_transformers import SentenceTransformer
import pandas as pd
import random
# Load original data
df = pd.read_csv("/content/flickr30k_translated_3k_sentences.csv")

# Randomly sample 500 new rows
unseen_df = df.sample(500, random_state=999)

# Build pairs: positive and negative
pos_unseen = []
neg_unseen = []

for _, row in unseen_df.iterrows():
    pos_unseen.append((row['en_caption'], row['caption_es'], 1))
    pos_unseen.append((row['en_caption'], row['caption_ur'], 1))

# Build negatives from different rows
for _ in range(len(pos_unseen)):
    i, j = random.sample(range(len(unseen_df)), 2)
    c1 = unseen_df.iloc[i]['en_caption']
    c2 = unseen_df.iloc[j][random.choice(['caption_es', 'caption_zh', 'caption_ur'])]
    neg_unseen.append((c1, c2, 0))

# Combine and shuffle
all_unseen = pos_unseen + neg_unseen
random.shuffle(all_unseen)

df_unseen_pairs = pd.DataFrame(all_unseen, columns=['caption1', 'caption2', 'label'])

from sentence_transformers import SentenceTransformer
import torch
import numpy as np

labse = SentenceTransformer('sentence-transformers/LaBSE')

emb1 = labse.encode(df_unseen_pairs['caption1'].tolist(), convert_to_tensor=True, batch_size=64)
emb2 = labse.encode(df_unseen_pairs['caption2'].tolist(), convert_to_tensor=True, batch_size=64)

X_unseen = torch.cat([torch.abs(emb1 - emb2), emb1 * emb2], dim=1).cpu().numpy()
y_unseen = df_unseen_pairs['label'].values

from sklearn.metrics import accuracy_score, roc_auc_score, classification_report

y_pred_lr = clf.predict(X_unseen)
y_prob_lr = clf.predict_proba(X_unseen)[:, 1]

print("LR Accuracy:", accuracy_score(y_unseen, y_pred_lr))
print("LR ROC-AUC:", roc_auc_score(y_unseen, y_prob_lr))
print(classification_report(y_unseen, y_pred_lr))

from torch.utils.data import DataLoader, TensorDataset

X_unseen_tensor = torch.tensor(X_unseen).float().cuda()
y_unseen_tensor = torch.tensor(y_unseen).long().cuda()

unseen_loader = DataLoader(TensorDataset(X_unseen_tensor, y_unseen_tensor), batch_size=64)

acc, auc = evaluate(model, unseen_loader)
print(f"NN Accuracy on Unseen Data: {acc:.4f}, ROC-AUC: {auc:.4f}")



